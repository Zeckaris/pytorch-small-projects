{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ce1e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.9.0+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb8b420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A scalar has a dimension of 0\n",
    "scalar= torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c39396ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#ndim allows us to see the dimension of a tensor (and it is like attribute) while .item() shows the value\n",
    "print (scalar.ndim)\n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81a6b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# A vector has a single dimension which is usualy enclosed under a sing bracket like [] and can have an arbitrary number of elements\n",
    "vector= torch.tensor([1,2,3,4])\n",
    "print(vector.ndim)\n",
    "# print(vector.item()) -- you can not do like this because items is for scalars only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42969b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for dimension of tensors we count the depth of the tensor and this is done by counting open brackets until you hit the first closing bracket\n",
    "MTX0= torch.tensor([[1,2], [5,3]])\n",
    "MTX0.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acee310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for shape of tensors (which shows the size) first we can learn from the dimension how much number we are going to have like \n",
    "# for a dimension of 1 you can only have one number and  for a dimension of 2 you can have two numbers\n",
    "# then we count rows and put number of rows until we reach the inner most which we then put the number of columns\n",
    "MTX1= torch.tensor([[1,2], [5,3]])\n",
    "MTX1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d638cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1: tensor(42)\n",
      "Tensor1 ndim: 0\n",
      "Tensor1 shape: torch.Size([])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now try to answer the following ones:\n",
    "\n",
    "tensor1 = torch.tensor(42)\n",
    "print(\"Tensor1:\", tensor1)\n",
    "print(\"Tensor1 ndim:\", tensor1.ndim)   # your guess: \n",
    "print(\"Tensor1 shape:\", tensor1.shape) # your guess: \n",
    "print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8459a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor2: tensor([10, 20, 30, 40])\n",
      "Tensor2 ndim: 1\n",
      "Tensor2 shape: torch.Size([4])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor2 = torch.tensor([10, 20, 30, 40])\n",
    "print(\"Tensor2:\", tensor2)\n",
    "print(\"Tensor2 ndim:\", tensor2.ndim)   # your guess: \n",
    "print(\"Tensor2 shape:\", tensor2.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7465f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor3: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Tensor3 ndim: 2\n",
      "Tensor3 shape: torch.Size([2, 3])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor3 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"Tensor3:\", tensor3)\n",
    "print(\"Tensor3 ndim:\", tensor3.ndim)   # your guess: \n",
    "print(\"Tensor3 shape:\", tensor3.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72699b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor4: tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[ 7,  8],\n",
      "         [ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[13, 14],\n",
      "         [15, 16],\n",
      "         [17, 18]]])\n",
      "Tensor4 ndim: 3\n",
      "Tensor4 shape: torch.Size([3, 3, 2])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor4 = torch.tensor([\n",
    "    [[1,2],[3,4],[5,6]],\n",
    "    [[7,8],[9,10],[11,12]],\n",
    "    [[13,14],[15,16],[17,18]]\n",
    "])\n",
    "print(\"Tensor4:\", tensor4)\n",
    "print(\"Tensor4 ndim:\", tensor4.ndim)   # your guess: \n",
    "print(\"Tensor4 shape:\", tensor4.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcebca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor5: tensor([])\n",
      "Tensor5 ndim: 1\n",
      "Tensor5 shape: torch.Size([0])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor5 = torch.tensor([])\n",
    "print(\"Tensor5:\", tensor5)\n",
    "print(\"Tensor5 ndim:\", tensor5.ndim)   # your guess: \n",
    "print(\"Tensor5 shape:\", tensor5.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c6dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor6: tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5]])\n",
      "Tensor6 ndim: 2\n",
      "Tensor6 shape: torch.Size([5, 1])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor6 = torch.tensor([[1],[2],[3],[4],[5]])\n",
    "print(\"Tensor6:\", tensor6)\n",
    "print(\"Tensor6 ndim:\", tensor6.ndim)   # your guess: \n",
    "print(\"Tensor6 shape:\", tensor6.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0393acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor7: tensor([[10, 20, 30, 40, 50]])\n",
      "Tensor7 ndim: 2\n",
      "Tensor7 shape: torch.Size([1, 5])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor7 = torch.tensor([[10,20,30,40,50]])\n",
    "print(\"Tensor7:\", tensor7)\n",
    "print(\"Tensor7 ndim:\", tensor7.ndim)   # your guess: \n",
    "print(\"Tensor7 shape:\", tensor7.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc4b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor8: tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]]]])\n",
      "Tensor8 ndim: 4\n",
      "Tensor8 shape: torch.Size([2, 2, 2, 2])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor8 = torch.tensor([\n",
    "    [[[1,2],[3,4]],[[5,6],[7,8]]],\n",
    "    [[[9,10],[11,12]],[[13,14],[15,16]]]\n",
    "])\n",
    "print(\"Tensor8:\", tensor8)\n",
    "print(\"Tensor8 ndim:\", tensor8.ndim)   # your guess: \n",
    "print(\"Tensor8 shape:\", tensor8.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32bb8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor9: tensor([999])\n",
      "Tensor9 ndim: 1\n",
      "Tensor9 shape: torch.Size([1])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor9 = torch.tensor([999])\n",
    "print(\"Tensor9:\", tensor9)\n",
    "print(\"Tensor9 ndim:\", tensor9.ndim)   # your guess: \n",
    "print(\"Tensor9 shape:\", tensor9.shape) # your guess: \n",
    "print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b787db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor10: tensor([[[ 1,  2,  3,  4]],\n",
      "\n",
      "        [[ 5,  6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11, 12]]])\n",
      "Tensor10 ndim: 3\n",
      "Tensor10 shape: torch.Size([3, 1, 4])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor10 = torch.tensor([\n",
    "    [[1,2,3,4]],\n",
    "    [[5,6,7,8]],\n",
    "    [[9,10,11,12]]\n",
    "])\n",
    "print(\"Tensor10:\", tensor10)\n",
    "print(\"Tensor10 ndim:\", tensor10.ndim)   # your guess: \n",
    "print(\"Tensor10 shape:\", tensor10.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c0e16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6734, 0.4929, 0.2699],\n",
       "         [0.4113, 0.2068, 0.5279]]),\n",
       " 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for  generating random tensors\n",
    "MTX2=torch.rand(size=(2,3))\n",
    "MTX2, MTX2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63c4b98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.]]), 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors filled with 0's\n",
    "MTX3= torch.zeros(size=(1,3))\n",
    "MTX3, MTX3.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7faadce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors filled with 1's\n",
    "MTX4= torch.ones(size=(2,1))\n",
    "MTX4, MTX4.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2943aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3210452060.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  MTX5= torch.range(0,8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors in a range with start and end\n",
    "MTX5= torch.range(0,8)\n",
    "MTX5, MTX5.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27a38683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  5,  8, 11, 14]), 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors in a ragne but with step value too (which is specified at the end)\n",
    "MTX6= torch.arange(2, 15, 3)\n",
    "MTX6, MTX6.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03342755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO SEE THE DATA TYPE OF THE TENSORS WE CAN USE .dtype which acts as an attribute\n",
    "MTX6.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e09755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a lot of datatypes\n",
    "# torch.float  with different levels of precision like torch.float8, torch.float16, torch.float32, torch.float64\n",
    "# torch.int with different size and signs like torch.int8, torch.int16, torch.int32 , torch.int64\n",
    "# torch.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3cbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device attribute indicates what we are using for the executing: cpu, gpu\n",
    "# cuda is for gpu\n",
    "# by default we run on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bd95ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 6.], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor= torch.tensor([4.0, 6.0], device=None, dtype=torch.float64, requires_grad=False)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07566162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# to check if cuda is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e832c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3951, 0.9630, 0.9416, 0.0924],\n",
      "        [0.2698, 0.5099, 0.6711, 0.2456],\n",
      "        [0.0491, 0.9629, 0.0044, 0.7001]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# one of the most used  tools for getting information about a tensor are shape, dtype and device\n",
    "some_tensor = torch.rand(3, 4)\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe13b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple scalar addition:  tensor([[20, 30, 40],\n",
      "        [10, 70, 80]])\n",
      "The same shape tensor addition:  tensor([[2.7595, 3.4147, 4.6119],\n",
      "        [1.8587, 7.4450, 8.2923]])\n",
      "Broadcast additon example result:  tensor([[ 4,  8, 12],\n",
      "        [ 3, 12, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Manipulating tensors\n",
    "# basic operations\n",
    "#Addition\n",
    "MTX7= torch.tensor([[2,3,4], [1,7,8]])  #shape of [2,3]\n",
    "#Rule 1: simple scalar addition (it works for and shape)\n",
    "res1= MTX7 + 10\n",
    "print(\"Simple scalar addition: \",res2)\n",
    "#Rule 2: when tensors have the same shape\n",
    "MTX8= torch.rand(size=(2,3))\n",
    "RS1= MTX7 + MTX8\n",
    "print(\"The same shape tensor addition: \" ,RS1)\n",
    "# Broadcasting rule: Starting from the rightmost dimension, compare shapes:\n",
    "# For each dimension: if equal or one of them is 1 then addition works\n",
    "#lets generate a tensor that fulfils this\n",
    "MTX9= torch.tensor([[2,5,8]]) #shape [1, 3]\n",
    "RS2= MTX7 + MTX9\n",
    "print (\"Broadcast additon example result: \", RS2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aebc230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple scalar multiplication:  tensor([[20, 30, 40],\n",
      "        [10, 70, 80]])\n",
      "same shape multiplication:  tensor([[1.5191, 1.2441, 2.4477],\n",
      "        [0.8587, 3.1147, 2.3381]])\n",
      "Brodcast multiplication rule result:  tensor([[ 4, 15, 32],\n",
      "        [ 2, 35, 64]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise MULTIPLICATION\n",
    "res2= MTX7 * 10 \n",
    "print(\"Simple scalar multiplication: \", res2)\n",
    "# For others it follows the same rules as additon , it is multipliable if they have teh same shape or if it is brodcastible\n",
    "RS3 = MTX7 * MTX8\n",
    "print(\"same shape multiplication: \", RS3)\n",
    "RS4 = MTX7 * MTX9\n",
    "print(\"Brodcast multiplication rule result: \", RS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7423b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of matrix multiplication using '@':  tensor([[34, 19],\n",
      "        [29, 15]])\n",
      "Result of matrix multiplication using torch.matmul() :  tensor([[34, 19],\n",
      "        [29, 15]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "# For matrix multiplication to work the inner dimensions must match. the result of such multiplication has the shape of the outer dimensions\n",
    "MTX10= torch.tensor([[1,3,4], [2,5,1]]) #shape [2, 3]\n",
    "MTX11= torch.tensor([[2, 1], [4,2], [5,3]]) #shape [3, 2]\n",
    "# the above two tensor inner dimensions are 3 and 3 which is the last for the fist tensor and the first for the second tensor\n",
    "# Now since their inner dimensions match it works and the result will have a dimension of [2,2]\n",
    "RS5= MTX10 @ MTX11  # @ is matrix multiplication, we can use torch.matmul() too\n",
    "print(\"Result of matrix multiplication using '@': \", RS5)\n",
    "RS6= torch.matmul(MTX10, MTX11)  # a shortcut to this is torch.mm(MTX10 , MTX11)\n",
    "print(\"Result of matrix multiplication using torch.matmul() : \", RS6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae649528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3, -2, -1],\n",
       "        [-4,  2,  3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction , it is exactly the same as addition interms of the rules like brodcast and others\n",
    "res3= MTX7 - 5\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.5000, 2.0000],\n",
       "        [0.5000, 3.5000, 4.0000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division / follows exactly the same broadcasting rules as + - *\n",
    "# In an element wise divison same shape, broadcasting and scalar work\n",
    "# It is important to note that there is not matrix division , it is only element wise so no other rules like inner dimensions must match\n",
    "res4= MTX7 / 2\n",
    "res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "361b7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4],\n",
      "        [1, 7],\n",
      "        [8, 3]])\n",
      "Transposed matrix (how we do it for higher dimensions):  tensor([[2, 4],\n",
      "        [1, 7],\n",
      "        [8, 3]])\n",
      "torch.Size([2, 3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "# Transposition\n",
    "MTX12= torch.tensor([[2,1,8], [4,7,3]])\n",
    "#Since the above tensor is of 2 dimension we can do \n",
    "print(MTX12.T)\n",
    "# but if it was  another higher dimension it wont work so what we use is\n",
    "transposed_MTX12= MTX12.transpose(0, 1) # we use python indexing which starts from 0 but also pytorch uses negative indices ( it is better to use .T for 2 dimensions)\n",
    "print(\"Transposed matrix (how we do it for higher dimensions): \", transposed_MTX12)\n",
    "#for higher dimensions\n",
    "x = torch.randn(2,3,4,5)  # shape [2,3,4,5]\n",
    "\n",
    "# Swap last two dimensions\n",
    "y = x.transpose(-2,-1)  \n",
    "print(y.shape)  # [2,3,5,4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
