{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ce1e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.9.0+cu128'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8b420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A scalar has a dimension of 0\n",
    "scalar= torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39396ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#ndim allows us to see the dimension of a tensor (and it is like attribute) while .item() shows the value\n",
    "print (scalar.ndim)\n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a6b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# A vector has a single dimension which is usualy enclosed under a sing bracket like [] and can have an arbitrary number of elements\n",
    "vector= torch.tensor([1,2,3,4])\n",
    "print(vector.ndim)\n",
    "# print(vector.item()) -- you can not do like this because items is for scalars only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42969b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for dimension of tensors we count the depth of the tensor and this is done by counting open brackets until you hit the first closing bracket\n",
    "MTX0= torch.tensor([[1,2], [5,3]])\n",
    "MTX0.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acee310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for shape of tensors (which shows the size) first we can learn from the dimension how much number we are going to have like \n",
    "# for a dimension of 1 you can only have one number and  for a dimension of 2 you can have two numbers\n",
    "# then we count rows and put number of rows until we reach the inner most which we then put the number of columns\n",
    "MTX1= torch.tensor([[1,2], [5,3]])\n",
    "MTX1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d638cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1: tensor(42)\n",
      "Tensor1 ndim: 0\n",
      "Tensor1 shape: torch.Size([])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now try to answer the following ones:\n",
    "\n",
    "tensor1 = torch.tensor(42)\n",
    "print(\"Tensor1:\", tensor1)\n",
    "print(\"Tensor1 ndim:\", tensor1.ndim)   # your guess: \n",
    "print(\"Tensor1 shape:\", tensor1.shape) # your guess: \n",
    "print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor2: tensor([10, 20, 30, 40])\n",
      "Tensor2 ndim: 1\n",
      "Tensor2 shape: torch.Size([4])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor2 = torch.tensor([10, 20, 30, 40])\n",
    "print(\"Tensor2:\", tensor2)\n",
    "print(\"Tensor2 ndim:\", tensor2.ndim)   # your guess: \n",
    "print(\"Tensor2 shape:\", tensor2.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7465f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor3: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Tensor3 ndim: 2\n",
      "Tensor3 shape: torch.Size([2, 3])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tensor3 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"Tensor3:\", tensor3)\n",
    "print(\"Tensor3 ndim:\", tensor3.ndim)   # your guess: \n",
    "print(\"Tensor3 shape:\", tensor3.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72699b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor4: tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[ 7,  8],\n",
      "         [ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[13, 14],\n",
      "         [15, 16],\n",
      "         [17, 18]]])\n",
      "Tensor4 ndim: 3\n",
      "Tensor4 shape: torch.Size([3, 3, 2])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor4 = torch.tensor([\n",
    "    [[1,2],[3,4],[5,6]],\n",
    "    [[7,8],[9,10],[11,12]],\n",
    "    [[13,14],[15,16],[17,18]]\n",
    "])\n",
    "print(\"Tensor4:\", tensor4)\n",
    "print(\"Tensor4 ndim:\", tensor4.ndim)   # your guess: \n",
    "print(\"Tensor4 shape:\", tensor4.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcebca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor5: tensor([])\n",
      "Tensor5 ndim: 1\n",
      "Tensor5 shape: torch.Size([0])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor5 = torch.tensor([])\n",
    "print(\"Tensor5:\", tensor5)\n",
    "print(\"Tensor5 ndim:\", tensor5.ndim)   # your guess: \n",
    "print(\"Tensor5 shape:\", tensor5.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor6: tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5]])\n",
      "Tensor6 ndim: 2\n",
      "Tensor6 shape: torch.Size([5, 1])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor6 = torch.tensor([[1],[2],[3],[4],[5]])\n",
    "print(\"Tensor6:\", tensor6)\n",
    "print(\"Tensor6 ndim:\", tensor6.ndim)   # your guess: \n",
    "print(\"Tensor6 shape:\", tensor6.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0393acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor7: tensor([[10, 20, 30, 40, 50]])\n",
      "Tensor7 ndim: 2\n",
      "Tensor7 shape: torch.Size([1, 5])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor7 = torch.tensor([[10,20,30,40,50]])\n",
    "print(\"Tensor7:\", tensor7)\n",
    "print(\"Tensor7 ndim:\", tensor7.ndim)   # your guess: \n",
    "print(\"Tensor7 shape:\", tensor7.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor8: tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]]]])\n",
      "Tensor8 ndim: 4\n",
      "Tensor8 shape: torch.Size([2, 2, 2, 2])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor8 = torch.tensor([\n",
    "    [[[1,2],[3,4]],[[5,6],[7,8]]],\n",
    "    [[[9,10],[11,12]],[[13,14],[15,16]]]\n",
    "])\n",
    "print(\"Tensor8:\", tensor8)\n",
    "print(\"Tensor8 ndim:\", tensor8.ndim)   # your guess: \n",
    "print(\"Tensor8 shape:\", tensor8.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32bb8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor9: tensor([999])\n",
      "Tensor9 ndim: 1\n",
      "Tensor9 shape: torch.Size([1])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor9 = torch.tensor([999])\n",
    "print(\"Tensor9:\", tensor9)\n",
    "print(\"Tensor9 ndim:\", tensor9.ndim)   # your guess: \n",
    "print(\"Tensor9 shape:\", tensor9.shape) # your guess: \n",
    "print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b787db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor10: tensor([[[ 1,  2,  3,  4]],\n",
      "\n",
      "        [[ 5,  6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11, 12]]])\n",
      "Tensor10 ndim: 3\n",
      "Tensor10 shape: torch.Size([3, 1, 4])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor10 = torch.tensor([\n",
    "    [[1,2,3,4]],\n",
    "    [[5,6,7,8]],\n",
    "    [[9,10,11,12]]\n",
    "])\n",
    "print(\"Tensor10:\", tensor10)\n",
    "print(\"Tensor10 ndim:\", tensor10.ndim)   # your guess: \n",
    "print(\"Tensor10 shape:\", tensor10.shape) # your guess: \n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c0e16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9491, 0.6899, 0.4748],\n",
       "         [0.0495, 0.6998, 0.0589]]),\n",
       " 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for  generating random tensors\n",
    "MTX2=torch.rand(size=(2,3))\n",
    "MTX2, MTX2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4b98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.]]), 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors filled with 0's\n",
    "MTX3= torch.zeros(size=(1,3))\n",
    "MTX3, MTX3.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7faadce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.]]),\n",
       " 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors filled with 1's\n",
    "MTX4= torch.ones(size=(2,1))\n",
    "MTX4, MTX4.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2943aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3210452060.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  MTX5= torch.range(0,8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors in a range with start and end\n",
    "MTX5= torch.range(0,8)\n",
    "MTX5, MTX5.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a38683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  5,  8, 11, 14]), 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for generating tensors in a ragne but with step value too (which is specified at the end)\n",
    "MTX6= torch.arange(2, 15, 3)\n",
    "MTX6, MTX6.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03342755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO SEE THE DATA TYPE OF THE TENSORS WE CAN USE .dtype which acts as an attribute\n",
    "MTX6.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e09755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a lot of datatypes\n",
    "# torch.float  with different levels of precision like torch.float8, torch.float16, torch.float32, torch.float64\n",
    "# torch.int with different size and signs like torch.int8, torch.int16, torch.int32 , torch.int64\n",
    "# torch.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3cbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device attribute indicates what we are using for the executing: cpu, gpu\n",
    "# cuda is for gpu\n",
    "# by default we run on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd95ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 6.], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor= torch.tensor([4.0, 6.0], device=None, dtype=torch.float64, requires_grad=False)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07566162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# to check if cuda is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e832c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4727, 0.0134, 0.3407, 0.7281],\n",
      "        [0.8278, 0.3709, 0.0971, 0.5266],\n",
      "        [0.7118, 0.3000, 0.3832, 0.0333]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# one of the most used  tools for getting information about a tensor are shape, dtype and device\n",
    "some_tensor = torch.rand(3, 4)\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple scalar addition:  tensor([[12, 13, 14],\n",
      "        [11, 17, 18]])\n",
      "The same shape tensor addition:  tensor([[2.9310, 3.6624, 4.8638],\n",
      "        [1.5799, 7.3753, 8.4049]])\n",
      "Broadcast additon example result:  tensor([[ 4,  8, 12],\n",
      "        [ 3, 12, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Manipulating tensors\n",
    "# basic operations\n",
    "#Addition\n",
    "MTX7= torch.tensor([[2,3,4], [1,7,8]])  #shape of [2,3]\n",
    "#Rule 1: simple scalar addition (it works for and shape)\n",
    "res1= MTX7 + 10\n",
    "print(\"Simple scalar addition: \",res1)\n",
    "#Rule 2: when tensors have the same shape\n",
    "MTX8= torch.rand(size=(2,3))\n",
    "RS1= MTX7 + MTX8\n",
    "print(\"The same shape tensor addition: \" ,RS1)\n",
    "# Broadcasting rule: Starting from the rightmost dimension, compare shapes:\n",
    "# For each dimension: if equal or one of them is 1 then addition works\n",
    "#lets generate a tensor that fulfils this\n",
    "MTX9= torch.tensor([[2,5,8]]) #shape [1, 3]\n",
    "RS2= MTX7 + MTX9\n",
    "print (\"Broadcast additon example result: \", RS2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebc230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple scalar multiplication:  tensor([[20, 30, 40],\n",
      "        [10, 70, 80]])\n",
      "same shape multiplication:  tensor([[1.8619, 1.9873, 3.4553],\n",
      "        [0.5799, 2.6271, 3.2394]])\n",
      "Brodcast multiplication rule result:  tensor([[ 4, 15, 32],\n",
      "        [ 2, 35, 64]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise MULTIPLICATION\n",
    "res2= MTX7 * 10 \n",
    "print(\"Simple scalar multiplication: \", res2)\n",
    "# For others it follows the same rules as additon , it is multipliable if they have teh same shape or if it is brodcastible\n",
    "RS3 = MTX7 * MTX8\n",
    "print(\"same shape multiplication: \", RS3)\n",
    "RS4 = MTX7 * MTX9\n",
    "print(\"Brodcast multiplication rule result: \", RS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7423b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of matrix multiplication using '@':  tensor([[34, 19],\n",
      "        [29, 15]])\n",
      "Result of matrix multiplication using torch.matmul() :  tensor([[34, 19],\n",
      "        [29, 15]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "# For matrix multiplication to work the inner dimensions must match. the result of such multiplication has the shape of the outer dimensions\n",
    "MTX10= torch.tensor([[1,3,4], [2,5,1]]) #shape [2, 3]\n",
    "MTX11= torch.tensor([[2, 1], [4,2], [5,3]]) #shape [3, 2]\n",
    "# the above two tensor inner dimensions are 3 and 3 which is the last for the fist tensor and the first for the second tensor\n",
    "# Now since their inner dimensions match it works and the result will have a dimension of [2,2]\n",
    "RS5= MTX10 @ MTX11  # @ is matrix multiplication, we can use torch.matmul() too\n",
    "print(\"Result of matrix multiplication using '@': \", RS5)\n",
    "RS6= torch.matmul(MTX10, MTX11)  # a shortcut to this is torch.mm(MTX10 , MTX11)\n",
    "print(\"Result of matrix multiplication using torch.matmul() : \", RS6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae649528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3, -2, -1],\n",
       "        [-4,  2,  3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction , it is exactly the same as addition interms of the rules like brodcast and others\n",
    "res3= MTX7 - 5\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.5000, 2.0000],\n",
       "        [0.5000, 3.5000, 4.0000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division / follows exactly the same broadcasting rules as + - *\n",
    "# In an element wise divison same shape, broadcasting and scalar work\n",
    "# It is important to note that there is not matrix division , it is only element wise so no other rules like inner dimensions must match\n",
    "res4= MTX7 / 2\n",
    "res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4],\n",
      "        [1, 7],\n",
      "        [8, 3]])\n",
      "Transposed matrix (how we do it for higher dimensions):  tensor([[2, 4],\n",
      "        [1, 7],\n",
      "        [8, 3]])\n",
      "torch.Size([2, 3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "# Transposition\n",
    "MTX12= torch.tensor([[2,1,8], [4,7,3]])\n",
    "#Since the above tensor is of 2 dimension we can do \n",
    "print(MTX12.T)\n",
    "# but if it was  another higher dimension it wont work so what we use is\n",
    "transposed_MTX12= MTX12.transpose(0, 1) # we use python indexing which starts from 0 but also pytorch uses negative indices ( it is better to use .T for 2 dimensions)\n",
    "print(\"Transposed matrix (how we do it for higher dimensions): \", transposed_MTX12)\n",
    "#for higher dimensions\n",
    "x = torch.randn(2,3,4,5)  # shape [2,3,4,5]\n",
    "\n",
    "# Swap last two dimensions\n",
    "y = x.transpose(-2,-1)  \n",
    "print(y.shape)  # [2,3,5,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MXT13:  tensor([ 3,  5,  7,  9, 11, 13, 15, 17])\n",
      "Minimum value is:  tensor(3)\n",
      "Maximum value is:  tensor(17)\n",
      "Total sum results in to:  tensor(80)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregation operations\n",
    "# min, max, mean , sum\n",
    "MXT13= torch.arange(3,19,2)\n",
    "print(\"MXT13: \", MXT13)\n",
    "print(\"Minimum value is: \", MXT13.min())\n",
    "print(\"Maximum value is: \", MXT13.max())\n",
    "print(\"Total sum results in to: \", MXT13.sum())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fbd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value is:  tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "#Now for mean it is a little different as it involves dividing and this causes change in data type\n",
    "print(\"Mean value is: \", MXT13.to(torch.float32).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cce1ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value for an already floting data type tensor is:  tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "# So if the tensor is already in a floating point data type there is no need to convert it first\n",
    "MXT14= torch.arange(3,19,2, dtype=torch.float32)\n",
    "print(\"The mean value for an already floting data type tensor is: \", MXT14.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95d66500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value of this tensor occurs at:  tensor(3)\n",
      "The maximum value occurs at index:  tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# We can also find where the minimum and maxium values occur (index)\n",
    "# we use argmin and argmax \n",
    "MXT15=torch.tensor([2, 9,11,0, 15,18,3,6])\n",
    "print(\"The minimum value of this tensor occurs at: \", MXT15.argmin())\n",
    "print(\"The maximum value occurs at index: \", MXT15.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbae5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype initially:  torch.int64\n",
      "Data type of the new drived tensor:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Changing tensor data type\n",
    "MXT16= torch.arange(0, 9, 2)\n",
    "print(\"datatype initially: \", MXT16.dtype)\n",
    "MXT16prime= MXT16.type(torch.float32)\n",
    "print(\"Data type of the new drived tensor: \", MXT16prime.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d71e3",
   "metadata": {},
   "source": [
    "Can Any Numeric Tensor Type Be Changed to Another?\n",
    "\n",
    "Yes, numeric tensor types (float, int, etc.) can be converted to other numeric types.\n",
    "\n",
    "But the values may change due to:\n",
    "\n",
    "Precision loss (smaller floats)\n",
    "\n",
    "Truncation (float → int)\n",
    "\n",
    "Overflow (large values into small integer types)\n",
    "\n",
    "Integer tensors cannot be used for gradient-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad924c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  tensor([1., 2., 3., 4., 5., 6.]) torch.Size([6])\n",
      "shape:  tensor([[1., 2., 3., 4., 5., 6.]]) torch.Size([1, 6])\n",
      "shape:  tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.]]) torch.Size([6, 1])\n",
      "***************************************************\n",
      "shape:  tensor([[1., 2., 3., 4., 5., 6.]]) torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "# Reshape, stack, squeeze, unsqueeze,\n",
    "# reshape\n",
    "x= torch.arange(1.0, 7.0)\n",
    "print(\"shape: \", x,  x.shape)\n",
    "x_reshaped= x.reshape(1,6) # The inputs represent the dimension of the new tensor we want to create\n",
    "print(\"shape: \", x_reshaped,  x_reshaped.shape)\n",
    "\n",
    "x_reshaped= x.reshape(6,1)\n",
    "print(\"shape: \", x_reshaped,  x_reshaped.shape)\n",
    "print(\"***************************************************\")\n",
    "# we can also let it figure out the dimension , you do this by setting -1\n",
    "x_reshaped= x.reshape(1, -1)\n",
    "print(\"shape: \", x_reshaped,  x_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046d237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Stacking means combining multiple tensors along a new dimension.\n",
    "# You have multiple tensors of the same shape. You want to join them into one bigger tensor. Unlike concatenation, stacking always creates a new dimension.\n",
    "# The requirement for stacking is all tensors must have the same shape.\n",
    "a= torch.tensor([1,2,3])\n",
    "b= torch.tensor([4,5,6])\n",
    "stacked= torch.stack((a,b), dim=1) # we can also use dim=0 here\n",
    "print(stacked, stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape:  torch.Size([1, 3])\n",
      "when squeezing:  tensor([1, 2, 3]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "#Squeeze is used to remove all 1 dimensions in a tensor\n",
    "a= torch.tensor([[1,2,3]])\n",
    "print(\"a shape: \", a.shape)\n",
    "print(\"when squeezing: \", a.squeeze(), a.squeeze().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b0726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1, 2, 3]])  shape: torch.Size([1, 3])\n",
      "a unsqueezed: tensor([[[1, 2, 3]]])  shape: torch.Size([1, 1, 3])\n",
      "a unsqueezed dim 1: tensor([[[1, 2, 3]]])  shape: torch.Size([1, 1, 3])\n",
      "a unsqueezed dim 2: tensor([[[1],\n",
      "         [2],\n",
      "         [3]]])  shape: torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# To do the reverse of squeeze we use unsqueeze\n",
    "print(f\"a: {a}  shape: {a.shape}\")\n",
    "print(f\"a unsqueezed: {a.unsqueeze(0)}  shape: {a.unsqueeze(0).shape}\") # what makes it different is you get to specify on which dimension to add it\n",
    "print(f\"a unsqueezed dim 1: {a.unsqueeze(1)}  shape: {a.unsqueeze(1).shape}\")\n",
    "print(f\"a unsqueezed dim 2: {a.unsqueeze(2)}  shape: {a.unsqueeze(2).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4170f7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "y:  tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# permute is used for reordering the dimension of tensors\n",
    "x= torch.tensor([[1,2,3], [4,5,6]])\n",
    "y= x.permute(1,0) # this swaps row with column\n",
    "print(\"x: \" , x)\n",
    "print(\"y: \" , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f54036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(2, 3, 4)\n",
    "print(\"a: \",a, a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d48b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a permute along  2,0,1:  tensor([[[ 0,  4,  8],\n",
      "         [12, 16, 20]],\n",
      "\n",
      "        [[ 1,  5,  9],\n",
      "         [13, 17, 21]],\n",
      "\n",
      "        [[ 2,  6, 10],\n",
      "         [14, 18, 22]],\n",
      "\n",
      "        [[ 3,  7, 11],\n",
      "         [15, 19, 23]]]) torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"a permute along  2,0,1: \", a.permute(2,0,1), a.permute(2,0,1).shape)\n",
    "# 2 indicates  the third dimension (which was 4) so now we will have 4 rows at the higher level\n",
    "# 0 indicates the first dimension which was 2, so now we will have another 2 rows inside of those 4 rows\n",
    "# 1 indicates the second dimension which was 3 will now show the columns which there will be 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b59dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor(2)\n",
      "tensor([1, 4])\n"
     ]
    }
   ],
   "source": [
    "#Indexing\n",
    "x= torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(x[0]) # this will print the first row\n",
    "print(x[0][1]) # this will pring the first row second column\n",
    "print(x[:,0])\n",
    "# : → means take all elements along this dimension (so for the above example we consider all rows)\n",
    "#0 → take index 0 along the second dimension (dim 1, columns)   (so for the above example we will take the first element of all rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132aacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[[1],\n",
      "         [4],\n",
      "         [7]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x[:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensors & NumPy\n",
    "#torch.from_numpy()\n",
    "#torch.Tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb273735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a= np.arange(1,10)\n",
    "p= torch.from_numpy(a)\n",
    "a, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba11feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6]), array([1, 2, 3, 4, 5, 6]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsor= torch.tensor([1,2,3,4,5,6])\n",
    "numpy_array= tnsor.numpy()\n",
    "tnsor, numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53022ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1401, 0.8419, 0.2550])\n",
      "tensor([[0.5208, 0.8659, 0.8480],\n",
      "        [0.4947, 0.9785, 0.1366]])\n",
      "tensor([[0.0124, 0.5062, 0.9418],\n",
      "        [0.7618, 0.0990, 0.7127]])\n",
      "***********************************************************\n",
      "rndm4:  tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009]])\n",
      "rndm5:  tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009]])\n"
     ]
    }
   ],
   "source": [
    "# randomness and ensurring reproducability\n",
    "rndm1= torch.rand(3) # if we just put a number inside it will generate a dim 1 tensor with the quantity of random numbers you specified\n",
    "print(rndm1)\n",
    "rndm2= torch.rand(2,3) # now this will create a tensor with shape [2,3]\n",
    "print(rndm2)\n",
    "rndm3= torch.rand(2,3)\n",
    "print(rndm3) # rndm3 and rndm2 have been generated the same way but they are different because we used rand\n",
    "print(\"***********************************************************\")\n",
    "#But what if we want to get the same generated random number, for reproducibility\n",
    "#for such cases we use torch.manual_seed() and it takes any number and aslong as we use that seed we get the same result\n",
    "RANDOM_SEED=42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rndm4= torch.rand(2,3)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rndm5= torch.rand(2,3)\n",
    "print(\"rndm4: \",rndm4)\n",
    "print(\"rndm5: \",rndm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d9c465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Here we will see how to use GPU\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f402d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 23, 43, 10], device='cuda:0') cuda:0\n",
      "tensor([11, 23, 43, 10]) cpu\n"
     ]
    }
   ],
   "source": [
    "#this shows creating a tensor for cuda/gpu\n",
    "a= torch.tensor([11,23,43,10] , device=\"cuda:0\")\n",
    "print(a, a.device)\n",
    "# we can also change tensors from one device to another\n",
    "b= a.to(\"cpu\")\n",
    "print(b, b.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
