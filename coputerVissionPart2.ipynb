{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cd57ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok now first lets turn the last part model from computer vision to use a functional training and testing loop\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c95fe075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83645b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionModelV3 (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0= nn.Flatten()\n",
    "        self.layer1= nn.Linear(in_features=784, out_features=256)\n",
    "        self.layer2= nn.Linear(in_features=256, out_features=10)\n",
    "        self.relu= nn.ReLU()\n",
    "        \n",
    "    def forward(self, x:torch.Tensor)-> torch.Tensor:\n",
    "        result= self.layer0(x)\n",
    "        result= self.layer1(result)\n",
    "        result= self.relu(result)\n",
    "        result= self.layer2(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1a445",
   "metadata": {},
   "source": [
    "Now is the time to create functional training and testing loop\n",
    "# First lets define the parameters they are going to take\n",
    "So naturaly they would take the model, data(data loader), loss function , optimizer function, epoch, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0288071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def train_model(model:nn.Module,\n",
    "                data:torch.utils.data.DataLoader,\n",
    "                lossFn: nn.Module, \n",
    "                optimizer:torch.optim.Optimizer,\n",
    "                epochs:int,\n",
    "                accr_fun: Callable[[torch.Tensor, torch.Tensor], float],\n",
    "                device:torch.device):\n",
    "    model.to(device)\n",
    "\n",
    "    batch_avg_accuracy=[]\n",
    "    loss_per_epoch= []\n",
    "    clock_start= timer()\n",
    "    # Now a new info i got is the avg_ccr is not always exactly the same as true accuracy and only works when batch \n",
    "    # size is equal for all of them, to test this we will add another accuracy\n",
    "    dataset_accuracy= []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_correct =0\n",
    "        total_samples= 0\n",
    "        true_accuracy= 0\n",
    "        avg_loss= 0\n",
    "        avg_acc_batch=0\n",
    "        model.train()\n",
    "        for X , y in data:\n",
    "            X= X.to(device)\n",
    "            y= y.to(device)\n",
    "            logit= model(X)\n",
    "            preds= torch.argmax(logit, dim=1)\n",
    "            \n",
    "            \n",
    "            loss= lossFn(logit, y)\n",
    "\n",
    "            avg_acc_batch += accr_fun(y, preds)\n",
    "            avg_loss += loss.item()\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_samples += len(y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        avg_loss /= len(data)\n",
    "        avg_acc_batch /= len(data)\n",
    "        batch_avg_accuracy.append(avg_acc_batch)\n",
    "        loss_per_epoch.append(avg_loss)\n",
    "        true_accuracy= total_correct / total_samples\n",
    "        dataset_accuracy.append(true_accuracy)\n",
    "    \n",
    "    clock_stop= timer()\n",
    "    time_taken= clock_stop - clock_start\n",
    "        \n",
    "    return {\n",
    "        'batch_avg_accuracy': batch_avg_accuracy,\n",
    "        'loss_per_epoch': loss_per_epoch,\n",
    "        'time_taken' : time_taken,\n",
    "        'dataset_accuracy': dataset_accuracy\n",
    "    }\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d128808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define the accuracy function we mentioned as a parameter for the training loop\n",
    "def accuracy_function(correct:torch.Tensor, prediction: torch.Tensor)-> float:\n",
    "    rslt= (correct == prediction).sum().item()\n",
    "    size= len(correct)\n",
    "    return rslt/size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1fef9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model:nn.Module,\n",
    "               data:torch.utils.data.DataLoader,\n",
    "               lossFn: nn.Module,\n",
    "               device:torch.device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total_correct= 0\n",
    "    total_samples= 0\n",
    "    total_loss=0\n",
    "    with torch.inference_mode():\n",
    "        for X , y in data:\n",
    "            X= X.to(device)\n",
    "            y= y.to(device)\n",
    "            logits= model(X)\n",
    "            pred= torch.argmax(logits, dim=1)\n",
    "            total_correct += (y == pred).sum().item()\n",
    "            total_samples += len(y)\n",
    "            \n",
    "            loss= lossFn(logits, y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    accuracy= total_correct / total_samples\n",
    "    loss= total_loss / len(data)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'loss': loss\n",
    "    }\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f6688e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train= True,\n",
    "    download= True,\n",
    "    transform= ToTensor(),\n",
    "    target_transform= None\n",
    ")\n",
    "\n",
    "test_dataset= datasets.FashionMNIST(\n",
    "    root= 'data',\n",
    "    train= False,\n",
    "    download=True,\n",
    "    transform= ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2951b051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c2cc532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label= train_dataset[0]\n",
    "img.shape , label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28e18915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img= img.squeeze()\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow( img,cmap='gray')\n",
    "plt.title(train_dataset.classes[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9886843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b78ee1f0a92419bb131d5e69c31df66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_avg_accuracy': [0.8278, 0.8656833333333334, 0.8774333333333333, 0.8854166666666666, 0.8912833333333333], 'loss_per_epoch': [0.47777769082784655, 0.3663988682190577, 0.3315287455221017, 0.31042813672026, 0.29554639617800715], 'time_taken': 47.1048031119999, 'dataset_accuracy': [0.8278, 0.8656833333333334, 0.8774333333333333, 0.8854166666666666, 0.8912833333333333]}\n",
      "-----------------------------------------------------------\n",
      "{'accuracy': 0.8765, 'loss': 0.34171678337711875}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE=32\n",
    "train_data_batched= DataLoader(\n",
    "    train_dataset,\n",
    "    BATCH_SIZE,\n",
    "    shuffle=True\n",
    "    )\n",
    "test_data_batched= DataLoader(\n",
    "    test_dataset,\n",
    "    BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model_fsh= FashionModelV3()\n",
    "loss_fn= nn.CrossEntropyLoss()\n",
    "optimzr= torch.optim.Adam(params=model_fsh.parameters(), lr=0.002)\n",
    "EPOCHS= 5\n",
    "device= torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_result= train_model(model_fsh, train_data_batched, loss_fn, optimzr, EPOCHS, accuracy_function, device)\n",
    "print(train_result)\n",
    "print(\"-----------------------------------------------------------\")\n",
    "test_result= test_model(model_fsh, test_data_batched,loss_fn, device)\n",
    "print(test_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6db6d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
